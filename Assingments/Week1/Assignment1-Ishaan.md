# Will DL replace ML in near future?

As explained in Session 1, DL is an evolution of ML and deals with "advanced stuff" as against ML. The shear ability of DL to identify data features and output sounds, images, free text, etc instead of working with plain old numbers puts it in a different category altogether.

In my opinion, this question is wrong as it is wrong to compare an ant with an elephant just because they are both animals. And speaking of "near future", I am sure ML will be preferred for small applications that do not required as much resource and ability that DL aims to provide, 'cause why cut an apple with an axe?

-----------------------------------------------------

# Pros and Cons of the 3 types of ML

Obviously, content is copied off of the internet! But I understand everything written below :)

-----------------------------------------------------

## Part 1 : SUPERVISED LEARNING

### Pros
1. Supervised learning is a simple process with full control of variables and progress with the developer.
1. You can find out exactly how many outputs you could expect.
1. It is possible for you to be very specific about the definition of the classes, i.e. you can train the algorithm to make a perfect _"decision boundary"_ to distinguish different classes accurately.
1. After the entire training is completed, you don’t need to keep the training data wiht you. Instead, you can keep the decision boundary as a dictating rule.
1. Supervised learning can be very helpful in classification problems, or problems with one "play" variable.

### Cons
1. Supervised learning is limited to handling classification easily but not used much for other ML applications.
1. Supervised learning cannot give you unknown information from the training data like unsupervised learning can.
1. In the case of classification, if we give an input that is not from any of the classes in the training data, then the output may be a wrong class label.
1. Similarly, let’s say your training set does not include some examples that you want to have in a class. Then, when you use those examples after training, you might not get the correct class label as the output.
1. Usually, training needs a lot of computation time, so do the classification, especially if the data set is very large. This will test your machine’s efficiency and your patience as well.

-----------------------------------------------------

## Part 2 : UNSUPERVISED LEARNING

### Pros
1. Since no class labels are provided for classification, the algorithm will look for inout features and learn to give an appropriate output.
1. The potential of hidden patterns can be very powerful for the business or even detect extremely amazing facts, fraud detection etc.
1. The algorithm might provide an insight not normally thought about by humans as "puzzle pieces" to solve problems.
1. If you want to do grouping of some data that you don’t know much about, then, in that case, unsupervised learning will be useful.

### Cons
1. As seen in above explanation unsupervised learning is harder as compared to supervised learning.
1. As your input is unlabeled, your results will be less accurate.

-----------------------------------------------------

## Part 3 : REINFORCED LEARNING

### Pros
1. Reinforcement learning can be used to solve very complex problems that cannot be solved by conventional techniques.
1. This learning model is very similar to the learning of human beings. Hence, it is close to achieving perfection. The model can correct the errors occurred during the training process.
1. You are saved that pain to find a training data-set for your problem, which can be really difficult sometimes.

### Cons
1. Reinforcement learning is not preferable to use for solving simple problems.
1. Reinforcement learning needs a lot of data and a lot of computation. That is why it works really well in video games.
1. Reinforcement learning assumes the world is Markovian, which it is not. The Markovian model describes a sequence of possible events in which the probability of each event depends only on the state attained in the previous event, which is false many times. Hence, many initial "specimen" grow in generations which loads the physical system.